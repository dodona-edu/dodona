en:
  evaluations:
    show:
      view_evaluation: "Show evaluation"
      evaluation: "Evaluation"
      title: "Evaluation for %{series}"
      explanation_title: "How do I evaluate a submission?"
      explanation_part1_html: "In the summary table, you can click on the <i class='mdi mdi-chevron-right mdi-18'></i> icon next to an exercise. You will then be taken to an incompleted submission of a random student.
      If you wish, you can leave feedback on the code and mark the submission as completed. Note that you can also mark a submission as completed without leaving feedback. To get started, we already marked all exercises without submissions as completed."
      explanation_part2_html: "As a reminder, students will <b>not</b> be able see the given feedback until you click on the 'release feedback' button below."
      release: Release feedback
      unrelease: Unrelease feedback
      deadline_html: This evaluation of <b>%{users} students</b> contains the submissions of <b>%{exercises} exercises</b> with <b>%{deadline}</b> as a deadline.
      next_incomplete_feedback: Go to the next incomplete solution
      evaluation_progress: Evaluation progress
      evaluation_details: Evaluation details
      evaluation_details_info_html: This table gives an overview of all submissions in this evaluation.<br> The colored bar shows the status of the submission (no submission, correct or wrong) and the check mark inside the speech bubble if the submission was completed already.
      progress_html: "<b>%{feedback_count} of the %{feedback_total}</b> submissions have completed feedback."
      grading_details: Grade overview
      grading_details_info_html: This table shows the grade overview for the evaluation. The total per user is the sum of the scores for the exercises.<br> If the score is gray, the submission is not yet completed.
    new:
      exercises: Exercises
      create_evaluation: Evaluate series
      pick_deadline: Pick deadline
      explanation_title: "What is an evaluation?"
      explanation_html: "Evaluating a series is a structured way to give feedback on all submitted solutions of a series. Dodona keeps track of which submissions are already checked, so you can easily split work between multiple course administrators. The feedback you give isn't immediately visible for the students; you can decide when it is released."
      next: Next
    add_users:
      title: Select users
      explanation_title: "Why do I have to select users?"
      explanation_part1: "An evaluation consists out of exercises from a single exercise series coupled with a group of students. Using the buttons you can easily select all users of this course or only who submitted at least once to any of the exercises in this series."
      explanation_part2: "You can also add and remove individual students below by searching for their name or any label. You can also edit the users of this evaluation later on."
      users_in_course_html:
        one: "<h1>1 <small>student</small></h1> is registered for this course"
        other: "<h1>%{count} <small>students</small></h1> are registered for this course"
      users_submitted_html:
        one: "<h1>1 <small>student</small></h1> submitted at least once"
        other: "<h1>%{count} <small>students</small></h1> submitted at least once"
      select_users: "Select these users"
    edit:
      title: Edit evaluation
      evaluation_info: Evaluation info
    edit_users:
      users_selected: selected students
      users_selected_html:
        zero: "You have currently selected <b>zero users</b>."
        one: "You have currently selected <b>one user</b>."
        other: "You have currently selected <b>%{count} users</b>."
      short_users_selected:
        zero: "Zero users selected"
        one: "One user selected"
        other: "%{count} users selected"
      to_evaluation: To evaluation
      back_to_evaluation: Back to evaluation
      mass_edit: Which students do you want to evaluate?
      clear: Deselect all users
      add_enrolled: All enrolled students
      add_submitted: All students with submissions
    edit_score_items: Edit score items
    destroy: Delete evaluation
    download: Download grades
    form:
      deadline-help_html: "<p>The deadline is used to select the default submission you give feedback on. The last submission before this deadline is used.</p><p><b>Warning:</b> You can't change the deadline later, but you can select a different solution for individual students.</p>"
    evaluation_table:
      user: User
    evaluation_grade_table:
      user: User
      total: Total
      average: Average
    feedback_status:
      feedback_finished: evaluation completed
      feedback_unstarted: evaluation not yet completed
      submission_not-started: "No submission, "
      submission_correct: "Correct submission, "
      submission_wrong: "Wrong submission, "
    overview:
      title: Evaluation overview
      explanation: A course admin evaluated your submissions for the series "%{series}". For each exercise, your last submission before %{deadline} was automatically selected, but the course admin might have manually selected a different one. Note that this evaluation doesn't necessarily mean that feedback was added to all of your submissions.
      released: Feedback was added to your code.
      exercise: Exercise
      no_annotations: "# comments"
      feedback: "Feedback"
      grade: Grade
      annotation_count:
        zero: "No comments were added to your solution"
        one: "One comment"
        other: "%{count} comments"
      no_submission: "You had no timely submission for this exercise"
      invisible_total: "The total score was not released"
      no_grading: "This exercise was not graded"
    members_table:
      remove_users_consequences: "If these students already received feedback, it will be deleted. Are you sure want to remove these students?"
      status: Progress
    member_row:
      remove_user_consequences: "If this student already received feedback, that feedback will be deleted. Are you sure you want to remove this student?"
    user_progress:
      not_submitted: Not submitted
